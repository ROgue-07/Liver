# -*- coding: utf-8 -*-
"""Liver Disease.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E07IdvIeWEJ_teWYZN0OO8o6nDddwCX4
"""

from google.colab import drive
drive.mount('/content/drive')

# IMPORTING LIBRARIES
import numpy as np
import pandas as pd
from numpy import loadtxt
from sklearn.model_selection import train_test_split
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import  LogisticRegression
from sklearn.model_selection import RandomizedSearchCV
from sklearn.model_selection import GridSearchCV
from xgboost import XGBClassifier
from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, cohen_kappa_score, classification_report
from sklearn.metrics import roc_curve, auc, roc_auc_score
import matplotlib.pyplot as plt
#for oversampling
from imblearn.over_sampling import RandomOverSampler
from collections import Counter

data = pd.read_csv('/content/drive/MyDrive/Data Sets/Liver Disease/Liver Patient Dataset (LPD)_train.csv', encoding = 'unicode_escape')
datat = pd.read_excel("/content/drive/MyDrive/Data Sets/Liver Disease/test.csv.xlsx")
print(data.shape)
data.head()

datat.head()

data.columns=['age','gender','TB','DB','AAP','SGPT','SGOT','TP','ALB','A/G','Label']

data.isnull().sum()

data['gender'].replace('Female',1,inplace=True)
data.gender.replace('Male',0,inplace=True)
#null impute
data.age=data.age.fillna(data.age.mean())
data.gender=data.gender.fillna(1.0)
data.TB=data.TB.fillna(data.TB.mean())
data.ALB=data.ALB.fillna(data.ALB.mean())
data.DB=data.DB.fillna(data.DB.median())
data.AAP =data.AAP.fillna(data.AAP.median())
data.SGPT =data.SGPT.fillna(data.SGPT.median())
data.SGOT =data.SGOT.fillna(data.SGOT.median())
data.TP =data.TP.fillna(data.TP.median())
data.Label.replace(2,0,inplace=True)
data['A/G'] =data['A/G'].fillna(data['A/G'].median())

#oversampling on basis of label
X = data.iloc[:,:-1]
Y = data.iloc[:,-1]
Data_rs=RandomOverSampler(sampling_strategy='minority')
X_res, Y_res = Data_rs.fit_resample(X, Y)

print('Original dataset shape {}'.format(Counter(Y)))
print('Resampled dataset shape {}'.format(Counter(Y_res)))

np.random.seed(0)
X_train, X_test, Y_train, Y_test = train_test_split(X_res, Y_res, test_size=0.20,random_state=106)
print(X_train.shape)
print(X_test.shape)
print(Y_train.shape)
print(Y_test.shape)

"""**DECISION TREE SEGMENT**"""

#np.random.seed(0)
dt_model=DecisionTreeClassifier(random_state=101)
dt_model.fit(X_train, Y_train)

#Predict
#np.random.seed(0)
y_dt_pred = dt_model.predict(X_test)

print("DT Accuracy:",accuracy_score(Y_test, y_dt_pred))
print('DT Precision: %.3f' % precision_score(Y_test, y_dt_pred))
print('DT Recall: %.3f' % recall_score(Y_test, y_dt_pred))
print('DT F1 Score: %.3f' % f1_score(Y_test, y_dt_pred))
print('DT Confusion matrix: \n', confusion_matrix(Y_test, y_dt_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test, y_dt_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test, y_dt_pred))

#print(classification_report(Y_test, y_pred))
fprDT, tprDT, thresholdDT = roc_curve(Y_test, y_dt_pred)
roc_auc = auc(fprDT, thresholdDT)

plt.title('Receiver Operating Characteristic')
plt.plot(fprDT, tprDT, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_dt_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')

"""**USING RANDOMIZEDSEARCH-CV-DT **"""

# Number of trees in dt
# Number of features to consider at every split
max_features = ['auto', 'sqrt','log2']
# Maximum number of levels in tree
max_depth = [int(x) for x in np.linspace(10, 1000,10)]
# Minimum number of samples required to split a node
min_samples_split = [2, 5, 10,14]
# Minimum number of samples required at each leaf node
min_samples_leaf = [1, 2, 4,6,8]
# Create the random grid
dt_random_grid = {'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
              'criterion':['entropy','gini']}
print(dt_random_grid)

dt=DecisionTreeClassifier(random_state=101)
dt_randomcv=RandomizedSearchCV(estimator=dt,param_distributions=dt_random_grid,n_iter=100,cv=3,verbose=2,random_state=100)
dt_randomcv.fit(X_train,Y_train)

dt_randomcv.best_params_

dt_randomcv.best_estimator_

dt_best_random_model=dt_randomcv.best_estimator_

y_dt_rs_pred = dt_best_random_model.predict(X_test)

print("DT Accuracy:",accuracy_score(Y_test, y_dt_rs_pred))
print('DT Precision: %.3f' % precision_score(Y_test, y_dt_rs_pred))
print('DT Recall: %.3f' % recall_score(Y_test, y_dt_rs_pred))
print('DT F1 Score: %.3f' % f1_score(Y_test, y_dt_rs_pred))
print('DT Confusion matrix: \n', confusion_matrix(Y_test, y_dt_rs_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test, y_dt_rs_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test, y_dt_rs_pred))

#print(classification_report(Y_test, y_pred))
fprDTRS, tprDTRS, thresholdDTRS = roc_curve(Y_test, y_dt_rs_pred)
roc_auc = auc(fprDTRS, thresholdDTRS)

plt.title('Receiver Operating Characteristic')
plt.plot(fprDTRS, tprDTRS, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_dt_rs_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')



"""*USING GRIDDSEARCH-DT*"""

dt_param_grid = {
    'criterion': [dt_randomcv.best_params_['criterion']],
    'max_depth': [dt_randomcv.best_params_['max_depth']],
    'max_features': [dt_randomcv.best_params_['max_features']],
    'min_samples_leaf': [dt_randomcv.best_params_['min_samples_leaf'], 
                         dt_randomcv.best_params_['min_samples_leaf']+2, 
                         dt_randomcv.best_params_['min_samples_leaf'] + 4],
    'min_samples_split': [dt_randomcv.best_params_['min_samples_split'] - 2,
                          dt_randomcv.best_params_['min_samples_split'] - 1,
                          dt_randomcv.best_params_['min_samples_split'], 
                          dt_randomcv.best_params_['min_samples_split'] +1,
                          dt_randomcv.best_params_['min_samples_split'] + 2],
}

print(dt_param_grid)

dt=DecisionTreeClassifier()
dt_gridcv=GridSearchCV(estimator=dt,param_grid=dt_param_grid,n_jobs=-1,cv=10,verbose=2)
dt_gridcv.fit(X_train,Y_train)

dt_best_grid_model=dt_gridcv.best_estimator_

dt_best_grid_model

y_dt_gs_pred = dt_best_grid_model.predict(X_test)

print("DT Accuracy:",accuracy_score(Y_test, y_dt_gs_pred))
print('DT Precision: %.3f' % precision_score(Y_test, y_dt_gs_pred))
print('DT Recall: %.3f' % recall_score(Y_test, y_dt_gs_pred))
print('DT F1 Score: %.3f' % f1_score(Y_test, y_dt_gs_pred))
print('DT Confusion matrix: \n', confusion_matrix(Y_test, y_dt_gs_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test, y_dt_gs_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test, y_dt_gs_pred))

#print(classification_report(Y_test, y_pred))
fprDTGS, tprDTGS, thresholdDTGS = roc_curve(Y_test, y_dt_gs_pred)
roc_auc = auc(fprDTGS, thresholdDTGS)

plt.title('Receiver Operating Characteristic')
plt.plot(fprDTGS, tprDTGS, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_dt_gs_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')

"""**LOGISTIC REGRESSION SEGMENT**

> Indented block


"""

lr_model=LogisticRegression(random_state=101)
lr_model.fit(X_train, Y_train)

print(lr_model.intercept_)
print(lr_model.coef_)


#Predict
y_lr_pred = lr_model.predict(X_test)

from sklearn import metrics
print("LR Accuracy:",accuracy_score(Y_test, y_lr_pred))
print('LR Precision: %.3f' % precision_score(Y_test, y_lr_pred))
print('LR Recall: %.3f' % recall_score(Y_test, y_lr_pred))
print('LR F1 Score: %.3f' % f1_score(Y_test, y_lr_pred))
print('LR Confusion matrix: \n', confusion_matrix(Y_test, y_lr_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test,y_lr_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test,y_lr_pred))

#print(classification_report(Y_test, y_pred))
fprLR, tprLR, thresholdLR = roc_curve(Y_test, y_lr_pred)
roc_auc = auc(fprLR, thresholdLR)

plt.title('Receiver Operating Characteristic')
plt.plot(fprLR, tprLR, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_lr_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')

"""***USING RANDOMSEARCH-CV--LR***"""

penalty = ['l1', 'l2', 'elasticnet', 'none']
dual = [True , False]
class_weight = ['balanced', 'None']
max_iter = [100,200,250]
lr_random_grid = {'penalty': penalty, 'dual': dual, 'class_weight': class_weight, 'max_iter': max_iter}
print(lr_random_grid)

lr=LogisticRegression(random_state=101)
lr_randomcv=RandomizedSearchCV(estimator=lr,param_distributions=lr_random_grid,cv=3,verbose=2,random_state=101)
lr_randomcv.fit(X_train,Y_train)

lr_randomcv.best_params_

lr_randomcv.best_estimator_

lr_best_random_model=lr_randomcv.best_estimator_

lr_best_random_model=lr_randomcv.best_estimator_

y_lr_rs_pred = lr_best_random_model.predict(X_test)

print("LR Accuracy:",accuracy_score(Y_test, y_lr_rs_pred))
print('LR Precision: %.3f' % precision_score(Y_test, y_lr_rs_pred))
print('LR Recall: %.3f' % recall_score(Y_test, y_lr_rs_pred))
print('LR F1 Score: %.3f' % f1_score(Y_test, y_lr_rs_pred))
print('LR Confusion matrix: \n', confusion_matrix(Y_test, y_lr_rs_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test, y_lr_rs_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test, y_lr_rs_pred))

#print(classification_report(Y_test, y_pred))
fprLRRS, tprLRRS, thresholdLRRS = roc_curve(Y_test, y_lr_rs_pred)
roc_auc = auc(fprLRRS, thresholdLRRS)

plt.title('Receiver Operating Characteristic')
plt.plot(fprLRRS, tprLRRS, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_lr_rs_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')

"""***USING GRIDSEARCH-LR***"""

penalty = ['l1', 'l2', 'elasticnet', 'none']
dual = [True , False]
class_weight = ['balanced', 'None']
max_iter = [100,200,250]
lr_param_grid = {'penalty': penalty, 'dual': dual, 'class_weight': class_weight, 'max_iter': max_iter}

print(lr_param_grid)

lr=LogisticRegression()
lr_gridcv=GridSearchCV(estimator=lr,param_grid=lr_param_grid,n_jobs=-1,cv=10,verbose=2)
lr_gridcv.fit(X_train,Y_train)

lr_best_grid_model=lr_gridcv.best_estimator_

lr_best_grid_model

y_lr_gs_pred = lr_best_grid_model.predict(X_test)

print("LR Accuracy:",accuracy_score(Y_test, y_lr_gs_pred))
print('LR Precision: %.3f' % precision_score(Y_test, y_lr_gs_pred))
print('LR Recall: %.3f' % recall_score(Y_test, y_lr_gs_pred))
print('LR F1 Score: %.3f' % f1_score(Y_test, y_lr_gs_pred))
print('LR Confusion matrix: \n', confusion_matrix(Y_test, y_lr_gs_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test, y_lr_gs_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test, y_lr_gs_pred))

#print(classification_report(Y_test, y_pred))
fprLRGS, tprLRGS, thresholdLRGS = roc_curve(Y_test, y_lr_gs_pred)
roc_auc = auc(fprLRRS, thresholdLRRS)

plt.title('Receiver Operating Characteristic')
plt.plot(fprLRGS, tprLRGS, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_lr_gs_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')

"""NICHER TA BEKAR"""

print(metrics.mean_absolute_error(Y_test, y_lr_gs_pred)) 

print(metrics.mean_squared_error(Y_test, y_lr_gs_pred)) 

print(np.sqrt(metrics.mean_squared_error(Y_test, y_lr_gs_pred)))

"""**XGBOOST SEGMENT**"""

xg_model=XGBClassifier(random_state=101, n_jobs=1)
eval_set=[(X_test,Y_test)]
xg_model.fit(X_train, Y_train, early_stopping_rounds=10, eval_metric='logloss',eval_set=eval_set, verbose= True)
#xg_model.fit(X_train, Y_train)

y_xg_pred=xg_model.predict(X_test)

print("XG Accuracy:",accuracy_score(Y_test, y_xg_pred))
print('XG Precision: %.3f' % precision_score(Y_test, y_xg_pred))
print('XG Recall: %.3f' % recall_score(Y_test, y_xg_pred))
print('XG F1 Score: %.3f' % f1_score(Y_test, y_xg_pred))
print('XG Confusion matrix: \n', confusion_matrix(Y_test, y_xg_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test, y_xg_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test, y_xg_pred))

#print(classification_report(Y_test, y_pred))
fprXG, tprXG, thresholdXG = roc_curve(Y_test, y_xg_pred)
roc_auc = auc(fprXG, thresholdXG)

plt.title('Receiver Operating Characteristic')
plt.plot(fprXG, tprXG, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_xg_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')

from xgboost import plot_importance
plot_importance(xg_model)
plt.show()

import xgboost as xgb
plt.figure(figsize=(20,15))
xgb.plot_tree(xg_model, ax=plt.gca())

"""*****USING RANDOMSEARCH-CV--XGB*****"""

#for hyperparameter tuning

xg_RS_params={"learning_rate" :[0.05, 0.10, 0.15, 0.20, 0.25, 0.30],
           "max_depth" : [3,4,5,6,7,10,12,15],
           "min_child_weight": [1,5,9],
           "gamma" : [0.0,0.1,0.2,0.3,0.4,0.5]}
           #"colsample_bytree"  : [0.3 ,0.4 ,0.5 ,0.7]
           

print(xg_RS_params)

xg_rs_model = XGBClassifier()
xg_randomcv=RandomizedSearchCV(xg_rs_model, param_distributions=xg_RS_params, n_iter=5, n_jobs=-1, cv=5, verbose=2, scoring= 'roc_auc',random_state=102)
xg_randomcv.fit(X_train,Y_train)

xg_randomcv.best_estimator_

xg_randomcv.best_params_

xg_best_random_model= xg_randomcv.best_estimator_

y_xg_RS_pred = xg_best_random_model.predict(X_test)

print("XG Accuracy:",accuracy_score(Y_test, y_xg_RS_pred))
print('XG Precision: %.3f' % precision_score(Y_test, y_xg_RS_pred))
print('XG Recall: %.3f' % recall_score(Y_test,y_xg_RS_pred))
print('XG F1 Score: %.3f' % f1_score(Y_test, y_xg_RS_pred))
print('XG Confusion matrix: \n', confusion_matrix(Y_test,y_xg_RS_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test, y_xg_RS_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test, y_xg_RS_pred))

#print(classification_report(Y_test, y_pred))
fprXGRS, tprXGRS, thresholdXGRS = roc_curve(Y_test, y_xg_RS_pred)
roc_auc = auc(fprXGRS, thresholdXGRS)

plt.title('Receiver Operating Characteristic')
plt.plot(fprXGRS, tprXGRS, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_xg_RS_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')

"""***USING GRIDSEARCH-LR***"""

xg_gs_params= {"learning_rate" :[0.05, 0.10, 0.15, 0.20, 0.25, 0.30],
           "max_depth" : [3,4,5,6,7,10,12,15],
           "min_child_weight": [1,5,9],
           "gamma" : [0.0,0.1,0.2,0.3,0.4,0.5]}

print(xg_gs_params)

xg_gs_model= XGBClassifier()
#xg = xgb.XGBClassifier()
xg_gridcv = GridSearchCV(estimator=xg_gs_model, param_grid=xg_gs_params, n_jobs=-1, cv=5, scoring="roc_auc")
xg_gridcv.fit(X_train, Y_train)

xg_gridcv.best_estimator_

xg_gridcv.best_params_

xg_best_grid_model= xg_gridcv.best_estimator_

y_xg_gs_pred = xg_best_grid_model.predict(X_test)

print("XG Accuracy:",accuracy_score(Y_test, y_xg_gs_pred))
print('XG Precision: %.3f' % precision_score(Y_test, y_xg_gs_pred))
print('XG Recall: %.3f' % recall_score(Y_test,y_xg_gs_pred))
print('XG F1 Score: %.3f' % f1_score(Y_test, y_xg_gs_pred))
print('XG Confusion matrix: \n', confusion_matrix(Y_test, y_xg_gs_pred))
print('cohens kappa \n', cohen_kappa_score(Y_test, y_xg_gs_pred))
print('ROC_AUC score \n', roc_auc_score(Y_test, y_xg_gs_pred))

#print(classification_report(Y_test, y_pred))
fprXGGS, tprXGGS, thresholdXGGS = roc_curve(Y_test, y_xg_gs_pred)
roc_auc = auc(fprGS, thresholdGS)

plt.title('Receiver Operating Characteristic')
plt.plot(fprXGGS, tprXGGS, 'b', label = 'AUC = %0.2f' % roc_auc)
plt.legend(loc = 'lower right')
plt.plot([0, 1], [0, 1],'r--')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.ylabel('True Positive Rate')
plt.xlabel('False Positive Rate')
plt.show()

# Custom method for plotting the Confusion Matrix
import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Blues):
    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        print("Normalized confusion matrix")
    else:
        print('Confusion matrix, without normalization')

    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    fmt = '.2f' if normalize else 'd'
    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, format(cm[i, j], fmt),
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True label')
    plt.xlabel('Predicted label')
    plt.tight_layout()

# Plotting the confussion Matrix
confussionMatrixRF = confusion_matrix(Y_test, y_xg_gs_pred)
np.set_printoptions(precision=2)
plt.figure()
plot_confusion_matrix(confussionMatrixRF, classes=['Liver Disease','Normal'], title='Confusion Matrix')